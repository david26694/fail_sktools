{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:16.108052Z",
     "start_time": "2020-06-24T07:40:16.089502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.017287Z",
     "start_time": "2020-06-24T07:40:16.112132Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "from category_encoders.utils import TransformerWithTargetMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sktools\n",
    "\n",
    "from sktools import QuantileEncoder\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.028058Z",
     "start_time": "2020-06-24T07:40:18.020347Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    '''\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        #print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        #print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "def elapsed_time_mins (time1,time2):\n",
    "    elapsed = np.round(np.abs(time1-time2)/60,decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "def fit_pipe(pipe,pipe_grid,X,y,subsample=False,n_max=20_000,best_params=True):\n",
    "    \n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "    \n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(pipe, param_grid=pipe_grid, n_jobs = n_jobs, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    pipe_cv.fit(X,y)\n",
    "    \n",
    "    best_estimator = pipe_cv.best_estimator_.fit( X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "    \n",
    "    return best_estimator,grid_results,pipe_cv.best_params_\n",
    "\n",
    "\n",
    "def compare_results(grid_1_res, grid_2_res):\n",
    "    \n",
    "    all_results = (\n",
    "        grid_1_res\n",
    "        .melt()\n",
    "        .merge(\n",
    "            grid_2_res.melt(),\n",
    "            on='variable', \n",
    "            suffixes=('_te', '_pe')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    all_results = all_results[\n",
    "        all_results['variable'].str.contains('split')\n",
    "    ]\n",
    "    \n",
    "    test_results = wilcoxon(\n",
    "        all_results.value_pe,\n",
    "        all_results.value_te,\n",
    "        alternative='greater'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return test_results.pvalue.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:11.521898Z",
     "start_time": "2020-06-11T08:02:08.959333Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/stackoverflow.csv')\n",
    "\n",
    "d.ConvertedSalary = pd.to_numeric(d.ConvertedSalary,errors='coerce')\n",
    "\n",
    "d = d[d.ConvertedSalary.isna()!=True]\n",
    "\n",
    "\n",
    "\n",
    "d.to_csv('data/stackoverflow_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.042133Z",
     "start_time": "2020-06-24T07:40:18.030927Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    'data/house_kaggle.csv',\n",
    "    'data/stackoverflow_clean.csv',\n",
    "    'data/ks.csv',\n",
    "    'data/medical_payments_sample.csv',\n",
    "    'data/cauchy.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.063271Z",
     "start_time": "2020-06-24T07:40:18.050527Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    ['Id','BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2','BsmtFinSF2', 'BsmtUnfSF','LowQualFinSF','FullBath','HalfBath'],\n",
    "    ['Respondent','Salary'],\n",
    "    [],\n",
    "    ['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name','Number_of_Payments_Included_in_Total_Amount'],\n",
    "    []\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.076256Z",
     "start_time": "2020-06-24T07:40:18.069306Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    ['MSSubClass','MSZoning','LotShape','LandContour','Utilities','LotConfig','Neighborhood','BldgType','HouseStyle','YearBuilt','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','MasVnrType','Heating','HeatingQC'],\n",
    "    ['Country','Employment','FormalEducation','UndergradMajor','CompanySize','DevType','YearsCoding','LanguageWorkedWith','LanguageDesireNextYear','RaceEthnicity'],\n",
    "    ['category', 'main_category', 'currency','state','country'],\n",
    "    \n",
    "    ['Recipient_City', 'Recipient_State', 'Recipient_Zip_Code','Recipient_Country', 'Physician_Primary_Type',\n",
    "       'Physician_License_State_code1',\n",
    "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "       'Form_of_Payment_or_Transfer_of_Value','Nature_of_Payment_or_Transfer_of_Value'],\n",
    "    \n",
    "    ['value_1', 'value_2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.087861Z",
     "start_time": "2020-06-24T07:40:18.080974Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    ['SalePrice'],\n",
    "    ['ConvertedSalary'],\n",
    "    ['goal'],\n",
    "    ['Total_Amount_of_Payment_USDollars'],\n",
    "    ['target']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.100327Z",
     "start_time": "2020-06-24T07:40:18.093301Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic=time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns =['NameDataset',\n",
    "          # Scores\n",
    "          'enet_te_train_mae','enet_te_test_mae',\n",
    "          'enet_te_train_mse','enet_te_test_mse',\n",
    "          \n",
    "          'enet_pe_train_mae','enet_pe_test_mae',\n",
    "          'enet_pe_train_mse','enet_pe_test_mse',\n",
    "          \n",
    "          'xgb_te_train_mae','xgb_te_test_mae',\n",
    "          'xgb_te_train_mse','xgb_te_test_mse',\n",
    "          \n",
    "          'xgb_pe_train_mae','xgb_pe_test_mae',\n",
    "          'xgb_pe_train_mse','xgb_pe_test_mse',\n",
    "          \n",
    "          \n",
    "          'size',\n",
    "          \n",
    "          # Params\n",
    "          'enet_te_best_params','enet_pe_best_params',\n",
    "          # Time\n",
    "          'time_train_m']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:19.910962Z",
     "start_time": "2020-06-24T07:40:18.104900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------+----------+\n",
      "| Data   | Model   | Train   | Test   | pvalue   |\n",
      "|--------+---------+---------+--------+----------|\n",
      "+--------+---------+---------+--------+----------+\n",
      "(1460, 69)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| house | enet_te | 18961.9 | 20746.2 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| house | enet_pe | 19084.8 | 20803.6 | 0.999 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| house | xgbs_te | 5787.96 | 17268.1 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| house | xgbs_pe | 5750.38 | 17328.1 | 0.827 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(47702, 127)\n",
      "+-------+---------+-------+-------+-----+\n",
      "| stack | enet_te | 56126 | 81231 | nan |\n",
      "+-------+---------+-------+-------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| stack | enet_pe | 51901.9 | 71375.6 | 0.001 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| stack | xgbs_te | 35538.6 | 71863.8 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| stack | xgbs_pe | 37250.4 | 69145.6 | 0.006 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(100000, 8)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| ks.cs | enet_te | 69318.9 | 61340.8 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+-------+---------+-------+\n",
      "| ks.cs | enet_pe | 65568 | 57490.4 | 0.001 |\n",
      "+-------+---------+-------+---------+-------+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| ks.cs | xgbs_te | 66721.2 | 60779.3 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| ks.cs | xgbs_pe | 70675.4 | 64067.1 | 0.999 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(100000, 11)\n",
      "+-------+---------+---------+--------+-----+\n",
      "| medic | enet_te | 844.601 | 760.58 | nan |\n",
      "+-------+---------+---------+--------+-----+\n",
      "+-------+---------+---------+--------+-------+\n",
      "| medic | enet_pe | 637.225 | 527.33 | 0.001 |\n",
      "+-------+---------+---------+--------+-------+\n",
      "+-------+---------+---------+-------+-----+\n",
      "| medic | xgbs_te | 325.078 | 325.1 | nan |\n",
      "+-------+---------+---------+-------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| medic | xgbs_pe | 320.982 | 355.255 | 0.319 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(100000, 3)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| cauch | enet_te | 22.4652 | 24.5656 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| cauch | enet_pe | 21.5634 | 23.6261 | 0.001 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| cauch | xgbs_te | 23.3651 | 25.5576 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| cauch | xgbs_pe | 23.3154 | 25.5074 | 0.001 |\n",
      "+-------+---------+---------+---------+-------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tabulate(tabular_data=[], headers=['Data', 'Model', 'Train', 'Test', 'pvalue'], tablefmt=\"psql\"))\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "\n",
    "    \n",
    "    cv = RepeatedKFold(n_repeats=3, n_splits=4, random_state=42)\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    \n",
    "    if df.shape[0] > 100_000:\n",
    "        df = df.sample(n=100_000)\n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=drop[i])\n",
    "    \n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(df.drop(columns=target[i]), df[target[i]])\n",
    "   \n",
    "\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    enet_te,enet_te_grid_results,enet_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "    \n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'enet_te', score_enet_te_train, score_enet_te_test, np.nan]], tablefmt='psql'))\n",
    "\n",
    "    \n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.QuantileEncoder(cols= cols_enc[i],quantile=.50,m=0)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__quantile\":[.50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    enet_pe,enet_pe_grid_results,enet_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    pvalue = compare_results(enet_te_grid_results, enet_pe_grid_results)\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'enet_pe', score_enet_pe_train,score_enet_pe_test, pvalue]], tablefmt='psql'))\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # xgb + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    xgb_te,xgb_te_grid_results,xgb_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'xgbs_te ', score_xgb_te_train,score_xgb_te_test, np.nan]], tablefmt='psql'))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    # xgb + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    pe = sktools.QuantileEncoder(cols= cols_enc[i],quantile=0.5,m=0)\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__quantile\":[.50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    xgb_pe,xgb_pe_grid_results,xgb_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    pvalue = compare_results(xgb_te_grid_results, xgb_pe_grid_results)\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'xgbs_pe', score_xgb_pe_train,score_xgb_pe_test, pvalue]], tablefmt='psql'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_pe_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgb_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgbt_pe_grid_results',data[i][5:10]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add Results\n",
    "    resultados.append([data[i].split('/')[1],\n",
    "                       #Scores\n",
    "                       score_enet_te_train,score_enet_te_test,\n",
    "                       score_enet_te_train_mse,score_enet_te_test_mse,\n",
    "                       \n",
    "                       score_enet_pe_train,score_enet_pe_test,\n",
    "                       score_enet_pe_train_mse,score_enet_pe_test_mse,\n",
    "                       \n",
    "                       score_xgb_te_train,score_xgb_te_test,\n",
    "                       score_xgb_te_train_mse,score_xgb_te_test_mse,\n",
    "                       \n",
    "                       score_xgb_pe_train,score_xgb_pe_test,\n",
    "                       score_xgb_pe_train_mse,score_xgb_pe_test_mse,\n",
    "                       \n",
    "                       # Shape\n",
    "                       df.shape,\n",
    "                       \n",
    "                       # params\n",
    "                       enet_te_params,\n",
    "                       enet_pe_params,\n",
    "                       \n",
    "                       # Time\n",
    "                       elapsed_time_mins(tic,time.time())])\n",
    "    \n",
    "    \n",
    "resultados = pd.DataFrame(resultados,columns=columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack simplified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
